{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/I-scream-icecream/Finance-dashboard/blob/main/predictorv3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Install necessary libraries and setup localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3h9YBWcBbK6S",
        "outputId": "07ab7eee-a17b-4013-b970-1eb165e50cc9"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit yfinance pandas requests numpy matplotlib pandas_datareader keras scikit-learn selenium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!npm install -g localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd /content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dynamic Market Insights Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxbWRmu5YfZn",
        "outputId": "c7c3f206-7106-4fdf-838f-2d708bbab69f"
      },
      "outputs": [],
      "source": [
        "%%writefile DMIT.py\n",
        "\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import streamlit as st\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.models import Sequential, load_model\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import requests\n",
        "from io import StringIO\n",
        "import os\n",
        "\n",
        "url_link = 'https://finance.yahoo.com/quote/%5ENSEI/components'\n",
        "r = requests.get(url_link,headers={'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'})\n",
        "\n",
        "# Wrap the HTML content in StringIO\n",
        "html_content = StringIO(r.text)\n",
        "\n",
        "# Read the HTML content using pandas.read_html\n",
        "reader = pd.read_html(html_content)[0]\n",
        "\n",
        "dropdown = reader.Symbol.to_list()\n",
        "\n",
        "st.title('Dynamic Market Insights Tool v2')\n",
        "\n",
        "ticker = st.selectbox('Pick your assets',\n",
        "                          dropdown)\n",
        "\n",
        "start = st.date_input('Start', value = pd.to_datetime('2010-01-01'))\n",
        "end = st.date_input('End', value = pd.to_datetime('today'))\n",
        "\n",
        "df = yf.download(ticker,start,end)\n",
        "df = df.reset_index()\n",
        "\n",
        "# Describing data\n",
        "st.subheader(f'Data from {start} to {end}')\n",
        "st.write(df.describe())\n",
        "\n",
        "# Visualization\n",
        "\n",
        "st.subheader(f'Closing vs Time chart for {ticker} with 50MA & 200MA')\n",
        "\n",
        "ma50 = df['Adj Close'].rolling(50).mean()\n",
        "\n",
        "ma200 = df['Adj Close'].rolling(200).mean()\n",
        "\n",
        "fig1 = plt.figure(figsize = (12,6))\n",
        "plt.plot(df['Date'], df['Adj Close'])\n",
        "plt.plot(df['Date'], ma200, 'r', label='200-day MA')\n",
        "plt.plot(df['Date'], ma50, 'y', label='50-day MA')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Adj Close')\n",
        "plt.title('Close Price Over Time')\n",
        "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
        "plt.legend()\n",
        "st.pyplot(fig1)\n",
        "\n",
        "\n",
        "# Button to trigger LSTM model building\n",
        "if st.button('Build LSTM Model'):\n",
        "    # LSTM model building code\n",
        "    try:\n",
        "        st.subheader(f'Creating LSTM model for {ticker}. Please wait...')\n",
        "        data_training = pd.DataFrame(df['Adj Close'][0:int(len(df)*0.70)])\n",
        "        data_testing = pd.DataFrame(df['Adj Close'][int(len(df)*0.70): int(len(df))])\n",
        "\n",
        "        from sklearn.preprocessing import MinMaxScaler\n",
        "        scaler = MinMaxScaler(feature_range=(0,1))\n",
        "\n",
        "        data_training_array = scaler.fit_transform(data_training)\n",
        "\n",
        "        model_path = '/content/keras_model_{}_{}_to_{}.h5'.format(ticker, start, end)\n",
        "\n",
        "        if os.path.exists(model_path):\n",
        "            st.write(\"Model already exists. Continuing...\")\n",
        "            # Continue with your code here\n",
        "            model = load_model('keras_model_{}_{}_to_{}.h5'.format(ticker, start, end))\n",
        "        else:\n",
        "            # Create training sequences and labels\n",
        "            x_train = []\n",
        "            y_train = []\n",
        "\n",
        "            for i in range(100, data_training_array.shape[0]):\n",
        "                x_train.append(data_training_array[i - 100: i])\n",
        "                y_train.append(data_training_array[i, 0])\n",
        "\n",
        "            x_train, y_train = np.array(x_train), np.array(y_train)\n",
        "\n",
        "            model = Sequential()\n",
        "            model.add(LSTM(units=50, activation='relu', return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
        "            model.add(Dropout(0.2))\n",
        "\n",
        "            model.add(LSTM(units=60, activation='relu', return_sequences=True))\n",
        "            model.add(Dropout(0.3))\n",
        "\n",
        "            model.add(LSTM(units=80, activation='relu', return_sequences=True))\n",
        "            model.add(Dropout(0.4))\n",
        "\n",
        "            model.add(LSTM(units=120, activation='relu'))\n",
        "            model.add(Dropout(0.5))\n",
        "\n",
        "            model.add(Dense(units=1))\n",
        "\n",
        "            model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "            model.fit(x_train, y_train, epochs=50)\n",
        "\n",
        "            model.save(f'keras_model_{ticker}_{start}_to_{end}.h5')\n",
        "\n",
        "        past_100_days = data_training.tail(100)\n",
        "        final_df = past_100_days.append(data_testing, ignore_index=True)\n",
        "        input_data = scaler.fit_transform(final_df)\n",
        "\n",
        "        x_test = []\n",
        "        y_test = []\n",
        "\n",
        "        for i in range(100, input_data.shape[0]):\n",
        "          x_test.append(input_data[i-100: i])\n",
        "          y_test.append(input_data[i, 0])\n",
        "\n",
        "        x_test, y_test = np.array(x_test), np.array(y_test)\n",
        "        y_predicted = model.predict(x_test)\n",
        "\n",
        "        reverser = scaler.scale_[0]\n",
        "        scale_factor = 1/reverser\n",
        "        y_predicted = y_predicted * scale_factor\n",
        "        y_test = y_test * scale_factor\n",
        "\n",
        "        # Display success message\n",
        "        st.success(\"LSTM Model built successfully!\")\n",
        "\n",
        "        fig2 = plt.figure(figsize=(12,6))\n",
        "        plt.plot(y_test, 'b', label = 'Original Price')\n",
        "        plt.plot(y_predicted, 'r', label = 'Predicted Price')\n",
        "        plt.xlabel('Time')\n",
        "        plt.ylabel('Price')\n",
        "        plt.legend()\n",
        "        st.pyplot(fig2)\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        # Display error message\n",
        "        st.error(f\"Error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Forexfactory webscraper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!mkdir -p /content/pages\n",
        "%cd /content/pages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile forexfactory.py\n",
        "\n",
        "import base64\n",
        "import os\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import random\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "\n",
        "def create_driver():\n",
        "    user_agent_list = [\n",
        "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.131 Safari/537.36',\n",
        "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:90.0) Gecko/20100101 Firefox/90.0',\n",
        "        'Mozilla/5.0 (Macintosh; Intel Mac OS X 11.5; rv:90.0) Gecko/20100101 Firefox/90.0',\n",
        "        'Mozilla/5.0 (Windows NT 10.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.131 Safari/537.36',\n",
        "        'Mozilla/5.0 (Macintosh; Intel Mac OS X 11_5_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.131 Safari/537.36',\n",
        "        'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:90.0) Gecko/20100101 Firefox/90.0',\n",
        "        'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.131 Safari/537.36'\n",
        "    ]\n",
        "    user_agent = random.choice(user_agent_list)\n",
        "\n",
        "    browser_options = webdriver.ChromeOptions()\n",
        "    browser_options.add_argument(\"--no-sandbox\")\n",
        "    browser_options.add_argument(\"--headless\")\n",
        "    browser_options.add_argument(\"start-maximized\")\n",
        "    browser_options.add_argument(\"window-size=1900,6000\")\n",
        "    browser_options.add_argument(\"disable-gpu\")\n",
        "    browser_options.add_argument(\"--disable-software-rasterizer\")\n",
        "    browser_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "    browser_options.add_argument(f'user-agent={user_agent}')\n",
        "\n",
        "    driver = webdriver.Chrome(options=browser_options)\n",
        "\n",
        "    return driver\n",
        "\n",
        "def parse_data(driver, url):\n",
        "    driver.get(url)\n",
        "\n",
        "    data_table = driver.find_element(By.CLASS_NAME, \"calendar__table\")\n",
        "    value_list = []\n",
        "\n",
        "    for row in data_table.find_elements(By.TAG_NAME, \"tr\"):\n",
        "        row_data = list(filter(None, [td.text for td in row.find_elements(By.TAG_NAME, \"td\")]))\n",
        "        if row_data:\n",
        "            value_list.append(row_data)  # Append only if row_data has content\n",
        "\n",
        "    # Corrected variable name for consistency\n",
        "    result_list = []\n",
        "    currencies = ['CAD', 'JPY', 'USD', 'GBP', 'EUR', 'NZD', 'AUD', 'CHF', 'CNY']\n",
        "    for row in value_list:\n",
        "        if len(row) == 1:\n",
        "            result_list.append(row)\n",
        "        elif row[1] in currencies:\n",
        "            result_list.append([None] + row)  # Add None for missing Date\n",
        "        elif row[0] in currencies:\n",
        "            result_list.append([None, None] + row)  # Add None for both Date and Time\n",
        "        else:\n",
        "            result_list.append(row)  # Keep the row as is\n",
        "\n",
        "    # Create DataFrame with appropriate column names\n",
        "    df = pd.DataFrame(result_list, columns=['Date', 'Time', 'Currency', 'Impact', 'Actual', 'Forecast', 'Previous'])\n",
        "\n",
        "    # Save DataFrame to CSV\n",
        "    df.to_csv(\"table_data.csv\", index=False)\n",
        "    st.write(\"CSV file generated successfully!\")\n",
        "\n",
        "def get_binary_file_downloader_html(bin_file, file_label='File'):\n",
        "    with open(bin_file, 'rb') as f:\n",
        "        data = f.read()\n",
        "    b64_data = base64.b64encode(data).decode()\n",
        "    href = f'<a href=\"data:file/csv;base64,{b64_data}\" download=\"{bin_file}\">{file_label}</a>'\n",
        "    return href\n",
        "\n",
        "# Streamlit UI\n",
        "st.title('ForexFactory Web Scraper')\n",
        "\n",
        "if st.button('Scrape Data'):\n",
        "    with st.spinner('Scraping data...'):\n",
        "        driver = create_driver()\n",
        "        url = 'https://www.forexfactory.com/calendar'\n",
        "        parse_data(driver=driver, url=url)\n",
        "\n",
        "        # Display CSV file and provide download link\n",
        "        if os.path.exists(\"/content/table_data.csv\"):\n",
        "            st.subheader(\"CSV file generated:\")\n",
        "            df = pd.read_csv(\"table_data.csv\")\n",
        "            st.write(df)\n",
        "\n",
        "            st.markdown(get_binary_file_downloader_html(\"table_data.csv\", 'CSV file'), unsafe_allow_html=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd /content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Deploy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbY6-EOqbHWt",
        "outputId": "ee1c9184-0e05-4d7d-8831-e63038789861"
      },
      "outputs": [],
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYKI0hrtbI4u",
        "outputId": "760996db-8c29-422d-c01a-c4aea4fc1935"
      },
      "outputs": [],
      "source": [
        "!streamlit run DMIT.py & npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOSppE+QKA3/55dJyb3nUi5",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
